{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photo to Mood\n",
    "\n",
    "画像データについて、GracenoteのどのMoodに相当するかを判断するModelを作成します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# グラフが文章中に表示されるようにするおまじない\n",
    "%matplotlib inline\n",
    "\n",
    "# autoreload module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load local package\n",
    "import sys\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(os.path.join(current_path, \"../../\"))  # load project root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_url、moodを左端に設定したファイルから学習データを読み込みます。\n",
    "なお、今回値はRekognitionのスコアであり、全項目同じ範囲の値のため正規化は行いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building', 'city', 'clothing', 'downtown', 'maillot', 'swimwear']\n",
      "(13, 6)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_file = os.path.join(current_path, \"./data/training_data.txt\")\n",
    "ignore_column = 1\n",
    "header = []\n",
    "data = None\n",
    "\n",
    "with open(data_file, \"rb\") as f:\n",
    "    header = f.readline().decode(\"utf-8\").split()\n",
    "    data = np.genfromtxt(f, usecols=range(ignore_column, len(header)))\n",
    "    \n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "header = header[(ignore_column + 1):] # ignore column + y column\n",
    "\n",
    "print(header)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回扱うのは画像の分類問題になります。そこで、分類問題でよく使われるSupport Vector Machineを利用します。  \n",
    "特徴量の数が多いため、有効なものに限って使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('building', inf), ('clothing', inf), ('maillot', inf), ('swimwear', inf), ('downtown', -13539310061041850.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:112: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_count = 5\n",
    "get_headers = lambda s: [i_h[1] for i_h in enumerate(header) if s[i_h[0]]]\n",
    "\n",
    "selector = SelectKBest(f_classif, k=feature_count).fit(X, y)\n",
    "selected = selector.get_support()\n",
    "kbests = sorted(zip(get_headers(selected), selector.scores_[selected]), key=lambda h_s: h_s[1], reverse=True)\n",
    "print(kbests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データとモデルがそろったため、学習させてみます。  \n",
    "パラメーターはGrid Searchで探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 (+/-0.000) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 100}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 1}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 10}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 100}\n",
      "0.556 (+/-0.250) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 1}\n",
      "0.556 (+/-0.250) for {'gamma': 0.0001, 'kernel': 'rbf', 'C': 1}\n",
      "0.556 (+/-0.250) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 10}\n",
      "0.556 (+/-0.250) for {'gamma': 0.0001, 'kernel': 'rbf', 'C': 10}\n",
      "0.556 (+/-0.250) for {'gamma': 0.0001, 'kernel': 'rbf', 'C': 100}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00         2\n",
      "        1.0       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Develop\\env\\Python\\Miniconda3\\envs\\onpasha\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm\n",
    "\n",
    "X_c = X[:, selected]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_c, y, test_size=0.25, random_state=42)\n",
    "\n",
    "candidates = [{'kernel': [\"rbf\"], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100]},\n",
    "              {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(C=1), candidates, cv=2, scoring=\"f1\")\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "for params, mean_score, scores in sorted(clf.grid_scores_, key=lambda s: s[1], reverse=True):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() / 2, params))\n",
    "\n",
    "columns = get_headers(selected)\n",
    "model = clf.best_estimator_\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、学習させたモデルを保存します。アプリケーション側で、その結果を確認してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building', 'clothing', 'downtown', 'maillot', 'swimwear']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./machine.pkl',\n",
       " './machine.pkl_01.npy',\n",
       " './machine.pkl_02.npy',\n",
       " './machine.pkl_03.npy',\n",
       " './machine.pkl_04.npy',\n",
       " './machine.pkl_05.npy',\n",
       " './machine.pkl_06.npy',\n",
       " './machine.pkl_07.npy',\n",
       " './machine.pkl_08.npy',\n",
       " './machine.pkl_09.npy',\n",
       " './machine.pkl_10.npy',\n",
       " './machine.pkl_11.npy']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "print(columns)\n",
    "joblib.dump(model, \"./machine.pkl\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
